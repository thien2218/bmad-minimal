$schema: ../../.internal/task.schema.json
id: test-design
title: Test Design
version: 1.0.0
purpose: Create comprehensive test scenarios with appropriate test level recommendations for story implementation.
category: quality
agent: qa

inputs:
  required:
    - name: story_id
      type: story_id
      description: Story identifier in format {epic}.{story}
      pattern: "^\\d+\\.\\d+$"
      examples: ["1.3", "2.5"]
    - name: story_path
      type: path
      description: Path to story file from docs.subdirs.stories
      pattern: "{@docs.subdirs.stories}/{epic}.{story}-*.yaml"
    - name: story_title
      type: string
      description: Story title (derive from story file H1 if missing)
    - name: story_slug
      type: string
      description: Story slug (derive from title if missing - lowercase, hyphenated)
      pattern: "^[a-z0-9-]+$"

prerequisites:
  files:
    - "{story_path}"

process:
  mode: sequential
  steps:
    - id: ANALYZE-REQ
      title: Analyze Story Requirements
      description: Break down each acceptance criterion into testable scenarios
      action:
        type: analysis
        prompt: |
          For each AC:
          - Identify core functionality to test
          - Determine data variations needed
          - Consider error conditions
          - Note edge cases

    - id: APPLY-FRAMEWORK
      title: Apply Test Level Framework
      description: Determine appropriate test level for each scenario
      action:
        type: analysis
        prompt: |
          Apply test level criteria from test-levels-framework.yaml:
          - Unit: Pure logic, algorithms, calculations
          - Integration: Component interactions, DB operations
          - E2E: Critical user journeys, compliance

    - id: ASSIGN-PRIORITY
      title: Assign Test Priorities
      description: Classify tests by priority using matrix
      action:
        type: analysis
        prompt: |
          Apply priorities from test-priorities-matrix.yaml:
          - P0: Revenue-critical, security, compliance
          - P1: Core user journeys, frequently used
          - P2: Secondary features, admin functions
          - P3: Nice-to-have, rarely used

    - id: DESIGN-SCENARIOS
      title: Design Test Scenarios
      description: Create detailed test scenarios for each identified need
      action:
        type: analysis
        prompt: |
          For each test need, create:
          - ID: {epic}.{story}-{LEVEL}-{SEQ}
          - Requirement: AC reference
          - Priority: P0|P1|P2|P3
          - Level: unit|integration|e2e
          - Description: What is being tested
          - Justification: Why this level was chosen
          - Risk mitigation: Which risks are addressed

    - id: VALIDATE-COVERAGE
      title: Validate Test Coverage
      description: Ensure comprehensive coverage without redundancy
      action:
        type: validation
        validation:
          type: checklist
          required: true
        prompt: |
          Ensure:
          - Every AC has at least one test
          - No duplicate coverage across levels
          - Critical paths have multiple levels
          - Risk mitigations are addressed

    - id: CREATE-REPORT
      title: Create Test Design Document
      description: Generate comprehensive test design report
      action:
        type: file_operation
        operation: create
        target: "{@docs.subdirs.qa}/assessments/{epic}.{story}-test-design-{YYYYMMDD}.md"
        content: |
          # Test Design: Story {epic}.{story}
          
          Date: {date}
          Designer: Quinn (Test Architect)
          
          ## Test Strategy Overview
          
          - Total test scenarios: X
          - Unit tests: Y (A%)
          - Integration tests: Z (B%)
          - E2E tests: W (C%)
          - Priority distribution: P0: X, P1: Y, P2: Z
          
          ## Test Scenarios by Acceptance Criteria
          
          ### AC1: {description}
          
          #### Scenarios
          
          | ID | Level | Priority | Test | Justification |
          |---|---|---|---|---|
          | 1.3-UNIT-001 | Unit | P0 | Validate input format | Pure validation logic |
          | 1.3-INT-001 | Integration | P0 | Service processes request | Multi-component flow |
          | 1.3-E2E-001 | E2E | P1 | User completes journey | Critical path validation |
          
          ## Risk Coverage
          
          [Map test scenarios to identified risks if risk profile exists]
          
          ## Recommended Execution Order
          
          1. P0 Unit tests (fail fast)
          2. P0 Integration tests
          3. P0 E2E tests
          4. P1 tests in order
          5. P2+ as time permits

    - id: CREATE-GATE-BLOCK
      title: Generate Gate YAML Block
      description: Create test_design block for quality gate
      action:
        type: file_operation
        operation: create
        target: "test_design_block.yaml"
        content: |
          test_design:
            scenarios_total: X
            by_level:
              unit: Y
              integration: Z
              e2e: W
            by_priority:
              p0: A
              p1: B
              p2: C
            coverage_gaps: []

    - id: PRINT-REFERENCE
      title: Print Trace References
      description: Output references for trace-requirements task
      action:
        type: analysis
        prompt: |
          Print:
          Test design matrix: {@docs.subdirs.qa}/assessments/{epic}.{story}-test-design-{YYYYMMDD}.md
          P0 tests identified: {count}

outputs:
  artifacts:
    - name: test_design_document
      type: report
      path: "{@docs.subdirs.qa}/assessments/{epic}.{story}-test-design-{YYYYMMDD}.md"
      format: markdown
      description: Comprehensive test design document with scenarios
    - name: gate_test_block
      type: file
      path: "test_design_block.yaml"
      format: yaml
      description: Test design block for gate file

dependencies:
  data:
    - test-levels-framework.yaml
    - test-priorities-matrix.yaml

completion:
  criteria:
    - Every AC has test coverage
    - Test levels are appropriate
    - No duplicate coverage across levels
    - Priorities align with business risk
    - Test IDs follow naming convention
    - Scenarios are atomic and independent
  validations:
    - command: "test -f {@docs.subdirs.qa}/assessments/{epic}.{story}-test-design-{YYYYMMDD}.md"
      expected_output: "file exists"

metadata:
  author: Thien Huynh
  created: "2024-01-01"
  lastModified: "2024-01-01"
  tags:
    - testing
    - design
    - quality
    - scenarios
  complexity: moderate
  estimated_duration: "30m-1h"
